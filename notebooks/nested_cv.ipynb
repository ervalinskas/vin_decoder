{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pandas import Series, DataFrame, read_csv, concat\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from numpy import array, ndarray\n",
    "from typing import Tuple, List, Dict, Union, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vin(vin: str) -> str:\n",
    "    return vin[0:3]\n",
    "\n",
    "\n",
    "def get_vehicle_attrs(vin: str) -> str:\n",
    "    return vin[3:10]\n",
    "\n",
    "\n",
    "def vectorize_text(vectorizer: Union[CountVectorizer,HashingVectorizer,TfidfVectorizer],\n",
    "                   X_train: Series,\n",
    "                   X_valid: Series) -> Tuple[ndarray]:\n",
    "    X_train_featurized = vectorizer.fit_transform(X_train)\n",
    "    X_valid_featurized = vectorizer.transform(X_valid)\n",
    "    return (X_train_featurized, X_valid_featurized)\n",
    "\n",
    "\n",
    "def create_pools(X_train: ndarray,\n",
    "                 y_train: array,\n",
    "                 X_valid: ndarray,\n",
    "                 y_valid: array) -> Tuple[Pool]:\n",
    "    train = Pool(data=X_train, label=y_train)\n",
    "    valid = Pool(data=X_valid, label=y_valid)\n",
    "    return (train, valid)\n",
    "\n",
    "\n",
    "def train_clf(train: Pool,\n",
    "              learning_rate: float,\n",
    "              depth: int,\n",
    "              iterations: int,\n",
    "              class_names: Optional[array] = None,\n",
    "              valid: Optional[Pool] = None) -> CatBoostClassifier:\n",
    "    inner_model = CatBoostClassifier(objective=\"MultiClass\",\n",
    "                                    learning_rate=learning_rate,\n",
    "                                    depth=depth,\n",
    "                                    iterations=iterations,\n",
    "                                    random_seed=1,\n",
    "                                    eval_metric=\"Accuracy\",\n",
    "                                    use_best_model=False,\n",
    "                                    logging_level=\"Silent\",\n",
    "                                    class_names=class_names,\n",
    "                                    task_type=\"GPU\",\n",
    "                                    devices=\"0:1\")\n",
    "\n",
    "    inner_model.fit(train, eval_set=valid)\n",
    "    return inner_model\n",
    "\n",
    "\n",
    "def nested_cv(X: Series,\n",
    "              y: Series,\n",
    "              class_names: array,\n",
    "              vectorizers: List[Union[CountVectorizer,HashingVectorizer,TfidfVectorizer]],\n",
    "              grid: Dict,\n",
    "              n_splits: int = 5,\n",
    "              shuffle: bool = True,\n",
    "              random_state: int = 1) -> DataFrame:\n",
    "    # TODO: Use hyperopt for param tuning\n",
    "    cv_outer = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "    cv_inner = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    outer_result = []\n",
    "    outer_fold_idx = 1\n",
    "\n",
    "    # Outer loop\n",
    "    for outer_train_idx, outer_valid_idx in cv_outer.split(X, y):\n",
    "        X_outer_train, X_outer_valid = X.iloc[outer_train_idx], X.iloc[outer_valid_idx]\n",
    "        y_outer_train, y_outer_valid = y.iloc[outer_train_idx], y.iloc[outer_valid_idx]\n",
    "\n",
    "        inner_fold_idx = 1\n",
    "        all_inner_fold_results = []\n",
    "\n",
    "        print(f\"Running {outer_fold_idx} outer fold... \\n \")\n",
    "\n",
    "        # Inner loop\n",
    "        for inner_train_idx, inner_valid_idx in cv_inner.split(X_outer_train, y_outer_train):\n",
    "            X_inner_train, X_inner_valid = X.iloc[inner_train_idx], X.iloc[inner_valid_idx]\n",
    "            y_inner_train, y_inner_valid = y.iloc[inner_train_idx], y.iloc[inner_valid_idx]\n",
    "\n",
    "            inner_result = []\n",
    "\n",
    "            print(f\"Running {inner_fold_idx} inner fold... \\n \")\n",
    "\n",
    "            # Text-to-features loop\n",
    "            for inner_vectorizer in vectorizers.keys():\n",
    "                X_inner_train_featurized, X_inner_valid_featurized = vectorize_text(vectorizer=vectorizers[inner_vectorizer],\n",
    "                                                                                    X_train=X_inner_train,\n",
    "                                                                                    X_valid=X_inner_valid)\n",
    "\n",
    "                # Hyperparam tuning loop\n",
    "                for learning_rate in grid[\"learning_rate\"]:\n",
    "                    for depth in grid[\"depth\"]:\n",
    "                        for iterations in grid[\"iterations\"]:\n",
    "                            train_inner_pool, valid_inner_pool = create_pools(X_train=X_inner_train_featurized,\n",
    "                                                                              y_train=y_inner_train,\n",
    "                                                                              X_valid=X_inner_valid_featurized,\n",
    "                                                                              y_valid=y_inner_valid)\n",
    "\n",
    "                            inner_model = train_clf(train=train_inner_pool,\n",
    "                                                    valid=valid_inner_pool,\n",
    "                                                    learning_rate=learning_rate,\n",
    "                                                    depth=depth,\n",
    "                                                    iterations=iterations,\n",
    "                                                    class_names=class_names)\n",
    "\n",
    "                            inner_metrics = inner_model.eval_metrics(data=valid_inner_pool,\n",
    "                                                                    metrics=[\"Accuracy\"],\n",
    "                                                                    ntree_start=iterations-1)\n",
    "\n",
    "                            print(f\"\"\"Text to features method - {inner_vectorizer} | learning rate - {learning_rate} | depth - {depth} | iterations - {iterations} | Accuracy - {inner_metrics[\"Accuracy\"][0]} \\n\\n\"\"\")\n",
    "\n",
    "                            inner_result.append({\"outer-fold\": outer_fold_idx,\n",
    "                                                \"inner-fold\": inner_fold_idx,\n",
    "                                                \"vectorizer\": inner_vectorizer,\n",
    "                                                \"learning_rate\": learning_rate,\n",
    "                                                \"depth\": depth,\n",
    "                                                \"iterations\": iterations,\n",
    "                                                \"accuracy\": inner_metrics[\"Accuracy\"][0]})\n",
    "            inner_fold_idx += 1\n",
    "            inner_result_df = DataFrame(inner_result)\n",
    "            all_inner_fold_results.append(inner_result_df)\n",
    "\n",
    "        all_inner_fold_results_df = concat(all_inner_fold_results)\n",
    "        all_inner_fold_results_agg_df = (all_inner_fold_results_df\n",
    "                                        .groupby([\"vectorizer\", \"learning_rate\", \"depth\", \"iterations\"])[\"accuracy\"]\n",
    "                                        .agg(\"mean\")\n",
    "                                        .reset_index()\n",
    "                                        .rename(columns={\"accuracy\": \"mean_accuracy\"}))\n",
    "\n",
    "        best_inner_params = all_inner_fold_results_agg_df[all_inner_fold_results_agg_df[\"mean_accuracy\"] == all_inner_fold_results_agg_df[\"mean_accuracy\"].max()].to_dict(\"records\")[0]\n",
    "\n",
    "        X_outer_train_featurized, X_outer_valid_featurized = vectorize_text(vectorizer=vectorizers[best_inner_params[\"vectorizer\"]],\n",
    "                                                                            X_train=X_outer_train,\n",
    "                                                                            X_valid=X_outer_valid)\n",
    "\n",
    "        train_outer_pool, valid_outer_pool = create_pools(X_train=X_outer_train_featurized,\n",
    "                                                          y_train=y_outer_train,\n",
    "                                                          X_valid=X_outer_valid_featurized,\n",
    "                                                          y_valid=y_outer_valid)\n",
    "\n",
    "        outer_model = train_clf(train=train_outer_pool,\n",
    "                                valid=valid_outer_pool,\n",
    "                                learning_rate=best_inner_params[\"learning_rate\"],\n",
    "                                depth=best_inner_params[\"depth\"],\n",
    "                                iterations=best_inner_params[\"iterations\"],\n",
    "                                class_names=class_names)\n",
    "\n",
    "        # Outer model evaluation\n",
    "        outer_metrics = outer_model.eval_metrics(data=valid_outer_pool,\n",
    "                                                 metrics=[\"Accuracy\"],\n",
    "                                                 ntree_start=best_inner_params[\"iterations\"] - 1)\n",
    "\n",
    "        outer_result.append({\"outer-fold\": outer_fold_idx,\n",
    "                             \"vectorizer\": best_inner_params[\"vectorizer\"],\n",
    "                             \"learning_rate\": best_inner_params[\"learning_rate\"],\n",
    "                             \"depth\": best_inner_params[\"depth\"],\n",
    "                             \"iterations\": best_inner_params[\"iterations\"],\n",
    "                             \"accuracy\": outer_metrics[\"Accuracy\"][0]})\n",
    "\n",
    "        outer_fold_idx += 1\n",
    "\n",
    "    # Generalization performance estimation\n",
    "    outer_folds_df = DataFrame(outer_result)\n",
    "    return outer_folds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vin</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3MW5R1J0XM8CXXXXX</td>\n",
       "      <td>3 Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4USBT33443LRXXXXX</td>\n",
       "      <td>Z Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5UXCR4C06M9FXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5UXCY6C04P9PXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5UXCY6C04P9PXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>WUAZZZF38N19XXXXX</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>WUAZZZF5XJA9XXXXX</td>\n",
       "      <td>A5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>WUAZZZF5XJA9XXXXX</td>\n",
       "      <td>A5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>WUAZZZFX9J79XXXXX</td>\n",
       "      <td>R8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>X4XKT294100YXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    vin     model\n",
       "0     3MW5R1J0XM8CXXXXX  3 Series\n",
       "1     4USBT33443LRXXXXX  Z Series\n",
       "2     5UXCR4C06M9FXXXXX  X Series\n",
       "3     5UXCY6C04P9PXXXXX  X Series\n",
       "4     5UXCY6C04P9PXXXXX  X Series\n",
       "...                 ...       ...\n",
       "1339  WUAZZZF38N19XXXXX        Q3\n",
       "1340  WUAZZZF5XJA9XXXXX        A5\n",
       "1341  WUAZZZF5XJA9XXXXX        A5\n",
       "1342  WUAZZZFX9J79XXXXX        R8\n",
       "1343  X4XKT294100YXXXXX  X Series\n",
       "\n",
       "[1344 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(\"../data/label_preprocessing/vin_model_pairs_w_labels.csv\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [some article](https://www.autocheck.com/vehiclehistory/images/vin-decode.jpg) as well as [Wikipedia](https://en.wikipedia.org/wiki/Vehicle_identification_number#Components), most VINs have 2 parts that shouldn\"t change despite the fact that though most manufacturers don\"t follow the standard.\n",
    "\n",
    "* Characters 1-3 capture WIM ([World Manufacturer identifier](https://en.wikipedia.org/wiki/Vehicle_identification_number#World_manufacturer_identifier))\n",
    "* Characters 4-9 should encapsulate vehicle attributes\n",
    "\n",
    "Everything else is a serial number of the vehicle or just irrelevant to the vehicle model classification problem. Based on this information, let\"s build features below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vin</th>\n",
       "      <th>model</th>\n",
       "      <th>wmi</th>\n",
       "      <th>vehicle_attrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3MW5R1J0XM8CXXXXX</td>\n",
       "      <td>3 Series</td>\n",
       "      <td>3MW</td>\n",
       "      <td>5R1J0XM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4USBT33443LRXXXXX</td>\n",
       "      <td>Z Series</td>\n",
       "      <td>4US</td>\n",
       "      <td>BT33443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5UXCR4C06M9FXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "      <td>5UX</td>\n",
       "      <td>CR4C06M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5UXCY6C04P9PXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "      <td>5UX</td>\n",
       "      <td>CY6C04P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5UXCY6C04P9PXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "      <td>5UX</td>\n",
       "      <td>CY6C04P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>WUAZZZF38N19XXXXX</td>\n",
       "      <td>Q3</td>\n",
       "      <td>WUA</td>\n",
       "      <td>ZZZF38N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>WUAZZZF5XJA9XXXXX</td>\n",
       "      <td>A5</td>\n",
       "      <td>WUA</td>\n",
       "      <td>ZZZF5XJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>WUAZZZF5XJA9XXXXX</td>\n",
       "      <td>A5</td>\n",
       "      <td>WUA</td>\n",
       "      <td>ZZZF5XJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>WUAZZZFX9J79XXXXX</td>\n",
       "      <td>R8</td>\n",
       "      <td>WUA</td>\n",
       "      <td>ZZZFX9J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>X4XKT294100YXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "      <td>X4X</td>\n",
       "      <td>KT29410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    vin     model  wmi vehicle_attrs\n",
       "0     3MW5R1J0XM8CXXXXX  3 Series  3MW       5R1J0XM\n",
       "1     4USBT33443LRXXXXX  Z Series  4US       BT33443\n",
       "2     5UXCR4C06M9FXXXXX  X Series  5UX       CR4C06M\n",
       "3     5UXCY6C04P9PXXXXX  X Series  5UX       CY6C04P\n",
       "4     5UXCY6C04P9PXXXXX  X Series  5UX       CY6C04P\n",
       "...                 ...       ...  ...           ...\n",
       "1339  WUAZZZF38N19XXXXX        Q3  WUA       ZZZF38N\n",
       "1340  WUAZZZF5XJA9XXXXX        A5  WUA       ZZZF5XJ\n",
       "1341  WUAZZZF5XJA9XXXXX        A5  WUA       ZZZF5XJ\n",
       "1342  WUAZZZFX9J79XXXXX        R8  WUA       ZZZFX9J\n",
       "1343  X4XKT294100YXXXXX  X Series  X4X       KT29410\n",
       "\n",
       "[1344 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"wmi\"] = df[\"vin\"].apply(get_vin)\n",
    "df[\"vehicle_attrs\"] = df[\"vin\"].apply(get_vehicle_attrs)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very few unique categories, hence we can skip sophisticated feature engineering methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3MW', '4US', '5UX', '5YM', 'TRU', 'WA1', 'WAU', 'WAV', 'WB1',\n",
       "       'WBA', 'WBS', 'WBX', 'WBY', 'WUA', 'X4X'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"wmi\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods considered:\n",
    "* One hot encoding (won't try)\n",
    "* Count Vectorizer (won't try)\n",
    "* Ngrams (need to try this out)\n",
    "* Hash Vectorizer (need to try this out)\n",
    "* TF-IDF (need to try this out)\n",
    "\n",
    "Rationale:\n",
    "\n",
    "* One Hot Encoding doesn't take into consideration frequence of token occurence as well as preceding and following tokens. The latter should be presumably important given the nature of the task\n",
    "* Count Vectorizer - don't consider preceding and following tokens. As it was mentioned, this should be very important for the VIN decoder task\n",
    "* Ngrams - takes into account unigrams, bigrams, trigrams, hence worth looking into\n",
    "* Hash Vectorizer - same as with Ngrams, but it takes on step further and applies hashing trick on top to reduce dimensionality\n",
    "* TF-IDF - lacks preceeding and succeeding token awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df[\"vehicle_attrs\"]\n",
    "wmis = df[\"wmi\"]\n",
    "targets = df[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erikas/Desktop/vin_decoder/venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/home/erikas/Desktop/vin_decoder/venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 outer fold... \n",
      " \n",
      "Running 1 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8662207357859532 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.862876254180602 \n",
      "\n",
      "\n",
      "Running 2 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8561872909698997 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8528428093645485 \n",
      "\n",
      "\n",
      "Running 3 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8053691275167785 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 25 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8120805369127517 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 25 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 15 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "/home/erikas/Desktop/vin_decoder/venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 2 outer fold... \n",
      " \n",
      "Running 1 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.862876254180602 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8595317725752508 \n",
      "\n",
      "\n",
      "Running 2 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8762541806020067 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8795986622073578 \n",
      "\n",
      "\n",
      "Running 3 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8825503355704698 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8758389261744967 \n",
      "\n",
      "\n",
      "Running 3 outer fold... \n",
      " \n",
      "Running 1 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erikas/Desktop/vin_decoder/venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8494983277591973 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8494983277591973 \n",
      "\n",
      "\n",
      "Running 2 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8561872909698997 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8595317725752508 \n",
      "\n",
      "\n",
      "Running 3 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8389261744966443 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 15 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 15 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 25 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 24 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8389261744966443 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 25 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 24 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outer-fold</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>iterations</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>700</td>\n",
       "      <td>0.825893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.15</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>0.808036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>700</td>\n",
       "      <td>0.837054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outer-fold vectorizer  learning_rate  depth  iterations  accuracy\n",
       "0           1    Bigrams           0.15     10         700  0.825893\n",
       "1           2    Bigrams           0.15      8         700  0.808036\n",
       "2           3    Bigrams           0.15     10         700  0.837054"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = targets.unique()\n",
    "# vectorizers = {\"Bigrams\": CountVectorizer(ngram_range=(2,2), analyzer=\"char\"),\n",
    "#                \"Hash vectorizer\": HashingVectorizer(ngram_range=(2,2), analyzer=\"char\"),\n",
    "#                \"TF-IDF\": TfidfVectorizer(ngram_range=(2,2), analyzer=\"char\")}\n",
    "# grid = {\"learning_rate\": [0.1, 0.15],\n",
    "#         \"depth\": [8, 10],\n",
    "#         \"iterations\": [700, 900]}\n",
    "\n",
    "vectorizers = {\"Bigrams\": CountVectorizer(ngram_range=(2,2), analyzer=\"char\")}\n",
    "grid = {\"learning_rate\": [0.15],\n",
    "        \"depth\": [8, 10],\n",
    "        \"iterations\": [700]}\n",
    "\n",
    "outer_folds_df = nested_cv(X=corpus, y=targets, class_names=class_names, vectorizers=vectorizers, grid=grid, n_splits=3)\n",
    "display(outer_folds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized accuracy - 0.8236607142857143 +/- 0.011951174407893587 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(f\"Generalized accuracy - {outer_folds_df['accuracy'].values.mean()} +/- {outer_folds_df['accuracy'].values.std()} \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>iterations</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.15</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vectorizer  learning_rate  depth  iterations  count\n",
       "0    Bigrams           0.15      8         700      1\n",
       "1    Bigrams           0.15     10         700      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparam_voting_df = (outer_folds_df\n",
    "                        .groupby([\"vectorizer\", \"learning_rate\", \"depth\", \"iterations\"])[\"outer-fold\"]\n",
    "                        .agg(\"count\")\n",
    "                        .reset_index()\n",
    "                        .rename(columns={\"outer-fold\": \"count\"}))\n",
    "display(hyperparam_voting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorizer': 'Bigrams',\n",
       " 'learning_rate': 0.15,\n",
       " 'depth': 10,\n",
       " 'iterations': 700}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = hyperparam_voting_df[hyperparam_voting_df[\"count\"] == hyperparam_voting_df[\"count\"].max()].drop(columns=[\"count\"]).to_dict(\"records\")[0]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(2, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(2, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(analyzer='char', ngram_range=(2, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = vectorizers[best_params.pop(\"vectorizer\")]\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f8fe56046a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_featurized = vectorizer.fit_transform(corpus)\n",
    "\n",
    "train = Pool(data=corpus_featurized, label=targets)\n",
    "train_clf(train=train, **best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
