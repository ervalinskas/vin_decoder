{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pandas import Series, DataFrame, read_csv, concat\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from numpy import array, ndarray\n",
    "from typing import Tuple, List, Dict, Union, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vin(vin: str) -> str:\n",
    "    return vin[0:3]\n",
    "\n",
    "\n",
    "def get_vehicle_attrs(vin: str) -> str:\n",
    "    return vin[3:10]\n",
    "\n",
    "\n",
    "def vectorize_text(vectorizer: Union[CountVectorizer,HashingVectorizer,TfidfVectorizer],\n",
    "                   X_train: Series,\n",
    "                   X_valid: Series) -> Tuple[ndarray]:\n",
    "    X_train_featurized = vectorizer.fit_transform(X_train)\n",
    "    X_valid_featurized = vectorizer.transform(X_valid)\n",
    "    return (X_train_featurized, X_valid_featurized)\n",
    "\n",
    "\n",
    "def create_pools(X_train: ndarray,\n",
    "                 y_train: array,\n",
    "                 X_valid: ndarray,\n",
    "                 y_valid: array) -> Tuple[Pool]:\n",
    "    train = Pool(data=X_train, label=y_train)\n",
    "    valid = Pool(data=X_valid, label=y_valid)\n",
    "    return (train, valid)\n",
    "\n",
    "\n",
    "def train_clf(train: Pool,\n",
    "              learning_rate: float,\n",
    "              depth: int,\n",
    "              iterations: int,\n",
    "              class_names: Optional[array] = None,\n",
    "              valid: Optional[Pool] = None) -> CatBoostClassifier:\n",
    "    inner_model = CatBoostClassifier(objective=\"MultiClass\",\n",
    "                                    learning_rate=learning_rate,\n",
    "                                    depth=depth,\n",
    "                                    iterations=iterations,\n",
    "                                    random_seed=1,\n",
    "                                    eval_metric=\"Accuracy\",\n",
    "                                    use_best_model=False,\n",
    "                                    logging_level=\"Silent\",\n",
    "                                    class_names=class_names,\n",
    "                                    devices=\"0:1\")\n",
    "\n",
    "    inner_model.fit(train, eval_set=valid)\n",
    "    return inner_model\n",
    "\n",
    "\n",
    "def nested_cv(X: Series,\n",
    "              y: Series,\n",
    "              class_names: array,\n",
    "              vectorizers: List[Union[CountVectorizer,HashingVectorizer,TfidfVectorizer]],\n",
    "              grid: Dict,\n",
    "              n_splits: int = 5,\n",
    "              shuffle: bool = True,\n",
    "              random_state: int = 1) -> DataFrame:\n",
    "    # TODO: Use hyperopt for param tuning\n",
    "    cv_outer = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "    cv_inner = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    outer_result = []\n",
    "    outer_fold_idx = 1\n",
    "\n",
    "    # Outer loop\n",
    "    for outer_train_idx, outer_valid_idx in cv_outer.split(X, y):\n",
    "        X_outer_train, X_outer_valid = X.iloc[outer_train_idx], X.iloc[outer_valid_idx]\n",
    "        y_outer_train, y_outer_valid = y.iloc[outer_train_idx], y.iloc[outer_valid_idx]\n",
    "\n",
    "        inner_fold_idx = 1\n",
    "        all_inner_fold_results = []\n",
    "\n",
    "        print(f\"Running {outer_fold_idx} outer fold... \\n \")\n",
    "\n",
    "        # Inner loop\n",
    "        for inner_train_idx, inner_valid_idx in cv_inner.split(X_outer_train, y_outer_train):\n",
    "            X_inner_train, X_inner_valid = X.iloc[inner_train_idx], X.iloc[inner_valid_idx]\n",
    "            y_inner_train, y_inner_valid = y.iloc[inner_train_idx], y.iloc[inner_valid_idx]\n",
    "\n",
    "            inner_result = []\n",
    "\n",
    "            print(f\"Running {inner_fold_idx} inner fold... \\n \")\n",
    "\n",
    "            # Text-to-features loop\n",
    "            for inner_vectorizer in vectorizers.keys():\n",
    "                X_inner_train_featurized, X_inner_valid_featurized = vectorize_text(vectorizer=vectorizers[inner_vectorizer],\n",
    "                                                                                    X_train=X_inner_train,\n",
    "                                                                                    X_valid=X_inner_valid)\n",
    "\n",
    "                # Hyperparam tuning loop\n",
    "                for learning_rate in grid[\"learning_rate\"]:\n",
    "                    for depth in grid[\"depth\"]:\n",
    "                        for iterations in grid[\"iterations\"]:\n",
    "                            train_inner_pool, valid_inner_pool = create_pools(X_train=X_inner_train_featurized,\n",
    "                                                                              y_train=y_inner_train,\n",
    "                                                                              X_valid=X_inner_valid_featurized,\n",
    "                                                                              y_valid=y_inner_valid)\n",
    "\n",
    "                            inner_model = train_clf(train=train_inner_pool,\n",
    "                                                    valid=valid_inner_pool,\n",
    "                                                    learning_rate=learning_rate,\n",
    "                                                    depth=depth,\n",
    "                                                    iterations=iterations,\n",
    "                                                    class_names=class_names)\n",
    "\n",
    "                            inner_metrics = inner_model.eval_metrics(data=valid_inner_pool,\n",
    "                                                                    metrics=[\"Accuracy\"],\n",
    "                                                                    ntree_start=iterations-1)\n",
    "\n",
    "                            print(f\"\"\"Text to features method - {inner_vectorizer} | learning rate - {learning_rate} | depth - {depth} | iterations - {iterations} | Accuracy - {inner_metrics[\"Accuracy\"][0]} \\n\\n\"\"\")\n",
    "\n",
    "                            inner_result.append({\"outer-fold\": outer_fold_idx,\n",
    "                                                \"inner-fold\": inner_fold_idx,\n",
    "                                                \"vectorizer\": inner_vectorizer,\n",
    "                                                \"learning_rate\": learning_rate,\n",
    "                                                \"depth\": depth,\n",
    "                                                \"iterations\": iterations,\n",
    "                                                \"accuracy\": inner_metrics[\"Accuracy\"][0]})\n",
    "            inner_fold_idx += 1\n",
    "            inner_result_df = DataFrame(inner_result)\n",
    "            all_inner_fold_results.append(inner_result_df)\n",
    "\n",
    "        all_inner_fold_results_df = concat(all_inner_fold_results)\n",
    "        all_inner_fold_results_agg_df = (all_inner_fold_results_df\n",
    "                                        .groupby([\"vectorizer\", \"learning_rate\", \"depth\", \"iterations\"])[\"accuracy\"]\n",
    "                                        .agg(\"mean\")\n",
    "                                        .reset_index()\n",
    "                                        .rename(columns={\"accuracy\": \"mean_accuracy\"}))\n",
    "\n",
    "        best_inner_params = all_inner_fold_results_agg_df[all_inner_fold_results_agg_df[\"mean_accuracy\"] == all_inner_fold_results_agg_df[\"mean_accuracy\"].max()].to_dict(\"records\")[0]\n",
    "\n",
    "        X_outer_train_featurized, X_outer_valid_featurized = vectorize_text(vectorizer=vectorizers[best_inner_params[\"vectorizer\"]],\n",
    "                                                                            X_train=X_outer_train,\n",
    "                                                                            X_valid=X_outer_valid)\n",
    "\n",
    "        train_outer_pool, valid_outer_pool = create_pools(X_train=X_outer_train_featurized,\n",
    "                                                          y_train=y_outer_train,\n",
    "                                                          X_valid=X_outer_valid_featurized,\n",
    "                                                          y_valid=y_outer_valid)\n",
    "\n",
    "        outer_model = train_clf(train=train_outer_pool,\n",
    "                                valid=valid_outer_pool,\n",
    "                                learning_rate=best_inner_params[\"learning_rate\"],\n",
    "                                depth=best_inner_params[\"depth\"],\n",
    "                                iterations=best_inner_params[\"iterations\"],\n",
    "                                class_names=class_names)\n",
    "\n",
    "        # Outer model evaluation\n",
    "        outer_metrics = outer_model.eval_metrics(data=valid_outer_pool,\n",
    "                                                 metrics=[\"Accuracy\"],\n",
    "                                                 ntree_start=best_inner_params[\"iterations\"] - 1)\n",
    "\n",
    "        outer_result.append({\"outer-fold\": outer_fold_idx,\n",
    "                             \"vectorizer\": best_inner_params[\"vectorizer\"],\n",
    "                             \"learning_rate\": best_inner_params[\"learning_rate\"],\n",
    "                             \"depth\": best_inner_params[\"depth\"],\n",
    "                             \"iterations\": best_inner_params[\"iterations\"],\n",
    "                             \"accuracy\": outer_metrics[\"Accuracy\"][0]})\n",
    "\n",
    "        outer_fold_idx += 1\n",
    "\n",
    "    # Generalization performance estimation\n",
    "    outer_folds_df = DataFrame(outer_result)\n",
    "    return outer_folds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vin</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3MW5R1J0XM8CXXXXX</td>\n",
       "      <td>3 Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4USBT33443LRXXXXX</td>\n",
       "      <td>Z Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5UXCR4C06M9FXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5UXCY6C04P9PXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5UXCY6C04P9PXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>WUAZZZF38N19XXXXX</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>WUAZZZF5XJA9XXXXX</td>\n",
       "      <td>A5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>WUAZZZF5XJA9XXXXX</td>\n",
       "      <td>A5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>WUAZZZFX9J79XXXXX</td>\n",
       "      <td>R8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>X4XKT294100YXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    vin     model\n",
       "0     3MW5R1J0XM8CXXXXX  3 Series\n",
       "1     4USBT33443LRXXXXX  Z Series\n",
       "2     5UXCR4C06M9FXXXXX  X Series\n",
       "3     5UXCY6C04P9PXXXXX  X Series\n",
       "4     5UXCY6C04P9PXXXXX  X Series\n",
       "...                 ...       ...\n",
       "1339  WUAZZZF38N19XXXXX        Q3\n",
       "1340  WUAZZZF5XJA9XXXXX        A5\n",
       "1341  WUAZZZF5XJA9XXXXX        A5\n",
       "1342  WUAZZZFX9J79XXXXX        R8\n",
       "1343  X4XKT294100YXXXXX  X Series\n",
       "\n",
       "[1344 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(\"../data/preprocessed_labels/vin_model_pairs_w_labels.csv\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [this article](https://www.autocheck.com/vehiclehistory/images/vin-decode.jpg) as well as [Wikipedia page](https://en.wikipedia.org/wiki/Vehicle_identification_number#Components), most VINs have 2 parts that remain consistent despite the fact that though most manufacturers don't follow the standard.\n",
    "\n",
    "* Characters 1-3 capture WIM ([World Manufacturer identifier](https://en.wikipedia.org/wiki/Vehicle_identification_number#World_manufacturer_identifier))\n",
    "* Characters 4-9 should encapsulate attributes of the vehicle\n",
    "\n",
    "The remainder is a serial number of the vehicle and thus for our heavily oversimplified classification problem (and also it's redacted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vin</th>\n",
       "      <th>model</th>\n",
       "      <th>wmi</th>\n",
       "      <th>vehicle_attrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3MW5R1J0XM8CXXXXX</td>\n",
       "      <td>3 Series</td>\n",
       "      <td>3MW</td>\n",
       "      <td>5R1J0XM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4USBT33443LRXXXXX</td>\n",
       "      <td>Z Series</td>\n",
       "      <td>4US</td>\n",
       "      <td>BT33443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5UXCR4C06M9FXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "      <td>5UX</td>\n",
       "      <td>CR4C06M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5UXCY6C04P9PXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "      <td>5UX</td>\n",
       "      <td>CY6C04P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5UXCY6C04P9PXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "      <td>5UX</td>\n",
       "      <td>CY6C04P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>WUAZZZF38N19XXXXX</td>\n",
       "      <td>Q3</td>\n",
       "      <td>WUA</td>\n",
       "      <td>ZZZF38N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>WUAZZZF5XJA9XXXXX</td>\n",
       "      <td>A5</td>\n",
       "      <td>WUA</td>\n",
       "      <td>ZZZF5XJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>WUAZZZF5XJA9XXXXX</td>\n",
       "      <td>A5</td>\n",
       "      <td>WUA</td>\n",
       "      <td>ZZZF5XJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>WUAZZZFX9J79XXXXX</td>\n",
       "      <td>R8</td>\n",
       "      <td>WUA</td>\n",
       "      <td>ZZZFX9J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>X4XKT294100YXXXXX</td>\n",
       "      <td>X Series</td>\n",
       "      <td>X4X</td>\n",
       "      <td>KT29410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    vin     model  wmi vehicle_attrs\n",
       "0     3MW5R1J0XM8CXXXXX  3 Series  3MW       5R1J0XM\n",
       "1     4USBT33443LRXXXXX  Z Series  4US       BT33443\n",
       "2     5UXCR4C06M9FXXXXX  X Series  5UX       CR4C06M\n",
       "3     5UXCY6C04P9PXXXXX  X Series  5UX       CY6C04P\n",
       "4     5UXCY6C04P9PXXXXX  X Series  5UX       CY6C04P\n",
       "...                 ...       ...  ...           ...\n",
       "1339  WUAZZZF38N19XXXXX        Q3  WUA       ZZZF38N\n",
       "1340  WUAZZZF5XJA9XXXXX        A5  WUA       ZZZF5XJ\n",
       "1341  WUAZZZF5XJA9XXXXX        A5  WUA       ZZZF5XJ\n",
       "1342  WUAZZZFX9J79XXXXX        R8  WUA       ZZZFX9J\n",
       "1343  X4XKT294100YXXXXX  X Series  X4X       KT29410\n",
       "\n",
       "[1344 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"wmi\"] = df[\"vin\"].apply(get_vin)\n",
    "df[\"vehicle_attrs\"] = df[\"vin\"].apply(get_vehicle_attrs)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very few unique categories, hence we can skip sophisticated feature engineering methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3MW', '4US', '5UX', '5YM', 'TRU', 'WA1', 'WAU', 'WAV', 'WB1',\n",
       "       'WBA', 'WBS', 'WBX', 'WBY', 'WUA', 'X4X'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"wmi\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Feature engineering__\n",
    "\n",
    "In order to convert VINs into features (since ML does't work directly on text), we'll consider the following methods:\n",
    "\n",
    "* One hot encoding\n",
    "* Count Vectorizer\n",
    "* Ngrams\n",
    "* Hash Vectorizer\n",
    "* TF-IDF\n",
    "\n",
    "Some observations:\n",
    "\n",
    "* One Hot Encoding doesn't take into consideration frequency of the token occurences as well as preceding and following tokens. The latter should presumably be important given the nature of the task.\n",
    "* Count Vectorizer - don't consider preceding and following tokens. As it was mentioned, this should be very important for the VIN decoder task due to the nature of the task.\n",
    "* Ngrams - takes into account unigrams, bigrams, trigrams, hence makes total sense to look into.\n",
    "* Hash Vectorizer - idea is the same of Ngrams, it just applies hashing trick on top to reduce dimensionality of text features.\n",
    "* TF-IDF - idea is the same of Ngrams, but additionally it weights each token based on it's frequency across all tokens. Generally tokens that appear rarely have more predictive power.\n",
    "\n",
    "Considering comments above, we'll exclusively focus on the following methods:\n",
    "\n",
    "* Ngrams\n",
    "* Hash Vectorizer\n",
    "* TF-IDF\n",
    "\n",
    "__N.B.__ We'll treat each character as a separate token.\n",
    "\n",
    "\n",
    "__Model training__\n",
    "\n",
    "__N.B.__ We'll have to use stratified [nested cross-validation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html) framework in order to train the model!\n",
    "\n",
    "Rationale behind the need of stratified nested CV:\n",
    "\n",
    "* Dataset is very small\n",
    "* We need to choose:\n",
    "    * Best text-to-features method\n",
    "    * Best hyperparameters\n",
    "    * Estimate generalization performance on unseen data\n",
    "* It's a [general recommendation](https://arxiv.org/abs/1811.12808) when datasets are this small\n",
    "* We have to use stratified sampling of data in order to keep category distributions between training / validation / test splits as similar as possible.\n",
    "\n",
    "Stratified nested CV:\n",
    "\n",
    "* We'll perform a normal cross validation by spliting the given dataset into training and validation datasets multiple times (outer loops).\n",
    "* Each training split from the previous cross validation will be split again into training and validation datasets (inner loops).\n",
    "* We'll use inner cross validation to choose the best text-to-features method + hyperparameters combination for the given outer training / validation split\n",
    "* Once the best vectorization method and hyperparam set for this outer loop is known, we'll retrain the model on the whole outer training split and measure its performance on outer validation split to obtain an unbiased performance for this 1 outer loop for.\n",
    "* We repeat the same procedure for all other outer cross validation splits.\n",
    "\n",
    "\n",
    "Last steps:\n",
    "\n",
    "* Once nested CV is finished, we'll average outer loop performance estimates to obtain generalization performance estimate. This will inform us what performance we can expect from deploying this model into production.\n",
    "* By taking a majority vote across all outer loops we'll pick the best hyperparams to deploy our model to prod\n",
    "\n",
    "![](notebooks/images/nested-cv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df[\"vehicle_attrs\"]\n",
    "wmis = df[\"wmi\"]\n",
    "targets = df[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikasvalinskas/Desktop/vin_decoder/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/Users/erikasvalinskas/Desktop/vin_decoder/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 outer fold... \n",
      " \n",
      "Running 1 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8595317725752508 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8461538461538461 \n",
      "\n",
      "\n",
      "Running 2 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8561872909698997 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8394648829431438 \n",
      "\n",
      "\n",
      "Running 3 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.802013422818792 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 25 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.7986577181208053 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 25 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 15 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "/Users/erikasvalinskas/Desktop/vin_decoder/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 2 outer fold... \n",
      " \n",
      "Running 1 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8394648829431438 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8561872909698997 \n",
      "\n",
      "\n",
      "Running 2 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8695652173913043 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8729096989966555 \n",
      "\n",
      "\n",
      "Running 3 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8557046979865772 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 22 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23, 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8691275167785235 \n",
      "\n",
      "\n",
      "Running 3 outer fold... \n",
      " \n",
      "Running 1 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikasvalinskas/Desktop/vin_decoder/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8528428093645485 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 24 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8528428093645485 \n",
      "\n",
      "\n",
      "Running 2 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.862876254180602 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 23 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8595317725752508 \n",
      "\n",
      "\n",
      "Running 3 inner fold... \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 15 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 15 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 8 | iterations - 700 | Accuracy - 0.8389261744966443 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 23 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 15 are not present in the train set. Perhaps, something is wrong with the data.\n",
      "Found only 25 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 24 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to features method - Bigrams | learning rate - 0.15 | depth - 10 | iterations - 700 | Accuracy - 0.8456375838926175 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found only 25 unique classes in the data, but have defined 26 classes. Probably something is wrong with data.\n",
      "Label(s) 24 are not present in the train set. Perhaps, something is wrong with the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outer-fold</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>iterations</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.15</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>0.814732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>700</td>\n",
       "      <td>0.799107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>700</td>\n",
       "      <td>0.852679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outer-fold vectorizer  learning_rate  depth  iterations  accuracy\n",
       "0           1    Bigrams           0.15      8         700  0.814732\n",
       "1           2    Bigrams           0.15     10         700  0.799107\n",
       "2           3    Bigrams           0.15     10         700  0.852679"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = targets.unique()\n",
    "# vectorizers = {\"Bigrams\": CountVectorizer(ngram_range=(2,2), analyzer=\"char\"),\n",
    "#                \"Hash vectorizer\": HashingVectorizer(ngram_range=(2,2), analyzer=\"char\"),\n",
    "#                \"TF-IDF\": TfidfVectorizer(ngram_range=(2,2), analyzer=\"char\")}\n",
    "# grid = {\"learning_rate\": [0.1, 0.15],\n",
    "#         \"depth\": [8, 10],\n",
    "#         \"iterations\": [700, 900]}\n",
    "\n",
    "# Reducing the hyperparam set to speed up the execution.\n",
    "vectorizers = {\"Bigrams\": CountVectorizer(ngram_range=(2,2), analyzer=\"char\")}\n",
    "grid = {\"learning_rate\": [0.15],\n",
    "        \"depth\": [8, 10],\n",
    "        \"iterations\": [700]}\n",
    "\n",
    "outer_folds_df = nested_cv(X=corpus, y=targets, class_names=class_names, vectorizers=vectorizers, grid=grid, n_splits=3)\n",
    "display(outer_folds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized accuracy - 0.8221726190476191 +/- 0.022494369728915102 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(f\"Generalized accuracy - {outer_folds_df['accuracy'].values.mean()} +/- {outer_folds_df['accuracy'].values.std()} \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>iterations</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.15</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vectorizer  learning_rate  depth  iterations  count\n",
       "0    Bigrams           0.15      8         700      1\n",
       "1    Bigrams           0.15     10         700      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparam_voting_df = (outer_folds_df\n",
    "                        .groupby([\"vectorizer\", \"learning_rate\", \"depth\", \"iterations\"])[\"outer-fold\"]\n",
    "                        .agg(\"count\")\n",
    "                        .reset_index()\n",
    "                        .rename(columns={\"outer-fold\": \"count\"}))\n",
    "display(hyperparam_voting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorizer': 'Bigrams',\n",
       " 'learning_rate': 0.15,\n",
       " 'depth': 10,\n",
       " 'iterations': 700}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = hyperparam_voting_df[hyperparam_voting_df[\"count\"] == hyperparam_voting_df[\"count\"].max()].drop(columns=[\"count\"]).to_dict(\"records\")[0]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(2, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(2, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(analyzer='char', ngram_range=(2, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = vectorizers[best_params.pop(\"vectorizer\")]\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1358cd330>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_featurized = vectorizer.fit_transform(corpus)\n",
    "\n",
    "train = Pool(data=corpus_featurized, label=targets)\n",
    "train_clf(train=train, **best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
